{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nisfatul Laili Rohmah_UTS Visi Komputer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "filenya = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "hy1QG-HuHp-N",
        "outputId": "5682d3c5-01d6-4a46-b816-6b03fee268b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c812e66-155c-45a2-9479-483a2c8d842f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c812e66-155c-45a2-9479-483a2c8d842f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Soal UTS Visi Komputer Kelas A dan B.txt to Soal UTS Visi Komputer Kelas A dan B (2).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('Soal UTS Visi Komputer Kelas A dan B.txt')"
      ],
      "metadata": {
        "id": "DZPHKKLwHtOE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "WKy-w1iqH3H_",
        "outputId": "36432ef1-ea4b-45f0-8ed3-c6e2ce969051"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffJOBSHEET VIII \\nBACKWARD CHAINING \\n8.1 Objectives \\nAfter completing this module, student will be able to: \\n1. Understand the concept of knowledge base inference engine \\n2. Simple implementation of backward chaining inference engine concept using python  language. \\n8.2 Backward Chaining \\nBackward chaining is an inference method that works from the goal and then backs  up following the necessary rules. Usually used in automatic theorem proofing, inference  engines, aiding in proof of truth, and other artificial intelligence applications. \\nBackward chaining Starting from a goal or hypothesis then backward from the  consequences to the antecedents to see if there is data that supports these consequences.  Backward chaining inference engine generates inference rules to find rules that have  consequences in accordance with the desired goals. If the antecedents of the rule are found  to be true they will be added to the list of goals. \\n  \\nThe backward chaining algorithm is also termed the FOL-BC-Ask algorithm.\\n  \\n\\nSample implementation \\nInput \\nThe program input is a file. The first line is the number of queries (n). This is followed by a query,  where one query per line. Each of these queries will be determined whether the query can be proven  from the knowledge base or not. \\nThe next line is the number of clauses that will be entered into the knowledge base (m). Below  that, followed by as many as m lines of clauses will become the knowledge base. These clauses are of two types: \\n(1) first order logic, for example: A (x, y) => B (x, y) \\n(2) atomic, for example: I (Amy) \\ninput example: \\ninput.txt \\n1 \\nB(John,Bob) \\n13 \\nA(x,y) => B(x,y) \\nG(x,y) => B(x,y) \\nC(c,d) => A(c,d) \\nB(x,y) => G(x,y) \\nF(y) => G(x,y) \\nG(x,y) ^ F(y) => H(x,y) \\nI(z) => F(z) \\nF(z) => I(z) \\nC(Jie,Joe) \\nC(Melissa,Mary) \\nG(John,Bob) \\nI(Amy) \\nF(Bob)\\n\\t\\n\\n\\n\\n8.3 Experiment \\nThe main program code starts from reading the input file according to the format above.  Then retrieve the query by removing the space character. Furthermore, the knowledge base  is taken and changed according to the determined standards.\\nfn=\"input.txt\"  \\nqueries = []  \\nknowledge_base = [] \\n\\t\\n\\n\\n\\nf1=open(fn, \"r\")  \\ninput = f1.readlines()  \\ninput = [x.strip() for x in input]  \\n  \\nfor i in range(1, int(input[0]) + 1):  \\n queries.append(input[i].replace(\" \", \"\"))  \\nfor i in range(int(input[0]) + 2, int(input[int(input[0]) + 1]) + int(input[0]) + 2):   knowledge_base.append(input[i].replace(\" \", \"\"))  \\nknowledge_base = standardize_variables(knowledge_base)  \\n  \\nkb = {}  \\nlist_of_predicates = []  \\nadd_to_kb(knowledge_base)  \\n  \\nfileOut = open(\"output.txt\", \"w\")  \\nfor query in queries:  \\n result = fol_bc_ask(query, {})  \\n if result != None:  \\n print(\"True\", result)  \\n fileOut.write(\"TRUE\" + \"\\\\n\")  \\n else:  \\n print(\"False\", result)  \\n fileOut.write(\"FALSE\" + \"\\\\n\")  \\n  \\nfileOut.close()  \\nf1.close \\n\\t\\n\\n\\n\\nStandardization of knowledge base variables is carried out by the following methods.\\ndef standardize_variables(knowledge_base):  \\n label = 0  \\n result_knowledge_base = []  \\n for rule in knowledge_base:  \\n variable_names = {}  \\n lhs = rule.partition(\\'=>\\')[0]  \\n rhs = rule.partition(\\'=>\\')[2]  \\n premise = []  \\n for x in lhs.split(\\'^\\'):  \\n premise.append(x)  \\n result_premise = \"\"  \\n for term in premise:  \\n args = [] \\n\\t\\n\\n\\n\\n result_term = \"\" + term.partition(\\'(\\')[0]   temp = term.partition(\\'(\\')[-1].rpartition(\\')\\')[0]   result_item = \"\"  \\n for item in temp.split(\\',\\'):  \\n args.append(item)  \\n if variable(item):  \\n if item not in variable_names:  \\n variable_names[item] = \"x\" + repr(label)   item = \"x\" + repr(label)  \\n label = label + 1  \\n else:  \\n item = variable_names[item]  \\n result_item = result_item + item + \",\"   result_item = result_item[:len(result_item) - 1]   result_term = result_term + \\'(\\' + result_item + \\')\\' + \\'^\\'   result_premise = result_premise + result_term   result_premise = result_premise[:len(result_premise) - 1]    \\n conclusion = []  \\n for x in rhs.split(\\'^\\'):  \\n conclusion.append(x)  \\n if conclusion != [\\'\\']:  \\n result_premise = result_premise + \"=>\"  \\n for term in conclusion:  \\n args = []  \\n result_term = \"\" + term.partition(\\'(\\')[0]   temp = term.partition(\\'(\\')[-1].rpartition(\\')\\')[0]   result_item = \"\"  \\n for item in temp.split(\\',\\'):  \\n args.append(item)  \\n if variable(item):  \\n if item not in variable_names:   variable_names[item] = \"x\" + repr(label)   item = \"x\" + repr(label)  label = label + 1  \\n else:  \\n item = variable_names[item]   result_item = result_item + item + \",\"   result_item = result_item[:len(result_item) - 1] \\n result_term = result_term + \\'(\\' + result_item + \\')\\' + \\'^\\'   result_premise = result_premise + result_term   result_premise = result_premise[:len(result_premise) - 1]    \\n result_knowledge_base.append(result_premise)  \\n return result_knowledge_base\\n\\t\\n\\n\\n\\nIn the process of adding a knowledge base, the premise and its conclusions are separated\\ndef add_to_kb(knowledge_base):  \\n global kb  \\n global list_of_predicates  \\n  \\n for sentence in knowledge_base:  \\n if \\'=>\\' not in sentence:  \\n predicate = sentence.partition(\\'(\\')[0]  \\n if predicate not in list_of_predicates:  \\n conc = []  \\n prem = []  \\n conc.append(\"=>\" + sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}  \\n list_of_predicates.append(predicate)  \\n else:  \\n conc = kb[predicate][\\'conc\\']  \\n prem = kb[predicate][\\'prem\\']  \\n conc.append(\"=>\" + sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}  \\n else:  \\n clauses = sentence.partition(\\'=>\\')  \\n list_of_premises = clauses[0].split(\\'^\\')  \\n conclusion = clauses[2]  \\n  \\n # for conclusion  \\n predicate = conclusion.partition(\\'(\\')[0]  \\n if predicate not in list_of_predicates:  \\n conc = []  \\n prem = []  \\n conc.append(sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}  \\n list_of_predicates.append(predicate)  \\n else:  \\n conc = kb[predicate][\\'conc\\']  \\n prem = kb[predicate][\\'prem\\']  \\n conc.append(sentence) \\n\\t\\n\\n\\n\\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}  \\n  \\n # for list_of_premises  \\n for premise in list_of_premises:  \\n predicate = premise.partition(\\'(\\')[0]  \\n if predicate not in list_of_predicates:  \\n conc = []  \\n prem = []  \\n prem.append(sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}  \\n list_of_predicates.append(predicate)  \\n else:  \\n conc = kb[predicate][\\'conc\\']  \\n prem = kb[predicate][\\'prem\\']  \\n prem.append(sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem} \\n\\t\\n\\n\\n\\nBackward chaining algorithm is also termed the FOL-BC-Ask algorithm (fists order logic - backward chaining – ask)\\ndef fol_bc_ask(query, theta):  \\n global kb  \\n global list_of_predicates  \\n global list_of_explored_rules  \\n  \\n print(\"Backward Chaining\")  \\n list_of_rules = fetch_rules(query)  \\n for rule in list_of_rules:  \\n print(\"taken RULE\", rule)  \\n list_of_explored_rules = []  \\n list_of_explored_rules.append(query)  \\n print(\"\\\\t\",query, \"added to list_of_explored_rules\")  \\n lhs = rule.partition(\\'=>\\')[0]  \\n rhs = rule.partition(\\'=>\\')[2]  \\n print(\"lhs: \", lhs, \" rhs: \", rhs)  \\n print(\"theta in rule\", theta)  \\n theta1 = unify(rhs, query, theta)  \\n if theta1 != None:  \\n list_of_premises = lhs.split(\\'^\\')  \\n print(\"list_of_premises: \", list_of_premises)  \\n theta2 = fol_bc_and(theta1, list_of_premises) \\n\\t\\n\\n\\n\\n if theta2 != None:  \\n return theta2  \\n  \\n print(\"None of the rules worked out\", query)  \\n return None\\n\\t\\n\\n\\n\\nOutput \\nIf running normally, the program output will display TRUE. \\nComplete code\\nfrom copy import deepcopy  \\n  \\nkb = {}  \\nlist_of_predicates = []  \\nlist_of_explored_rules = []  \\n  \\ndef fetch_rules(goal):  \\n global kb  \\n global list_of_predicates  \\n  \\n print(\"fetch_rules for goal:- \", goal)  \\n list_of_rules = []  \\n predicate = goal.partition(\\'(\\')[0]  \\n print(\"\\\\t\", predicate, kb[predicate][\\'conc\\'])  \\n list_of_rules = list_of_rules + kb[predicate][\\'conc\\']  \\n return list_of_rules  \\n  \\n  \\ndef subst(theta, first):  \\n print(\"\\\\tsubst: \", theta, first)  \\n predicate = first.partition(\\'(\\')[0]  \\n list = (first.partition(\\'(\\')[-1].rpartition(\\')\\')[0]).split(\\',\\')  \\n print(\"\\\\t\", list)  \\n for i in range(len(list)):  \\n if variable(list[i]):  \\n if list[i] in theta:  \\n list[i] = theta[list[i]]  \\n print(\"\\\\t\", predicate + \\'(\\' + \\',\\'.join(list) + \\')\\')  \\n return predicate + \\'(\\' + \\',\\'.join(list) + \\')\\'  \\n  \\n  \\ndef variable(x):  \\n if not isinstance(x, str):  \\n return False  \\n else: \\n\\t\\n\\n\\n\\n if x.islower():  \\n return True  \\n else:  \\n return False  \\n  \\n  \\ndef compound(x):  \\n if not isinstance(x, str):  \\n return False  \\n else:  \\n if \\'(\\' in x and \\')\\' in x:  \\n return True  \\n else:  \\n return False  \\n  \\n  \\ndef list(x):  \\n if not isinstance(x, str):  \\n return True  \\n else:  \\n return False  \\n  \\n  \\ndef unify_var(var, x, theta):  \\n print(\"IN unify_var\", var, x, theta)  \\n if var in theta:  \\n print(\"var in theta\", var, theta)   return unify(theta[var], x, theta)   elif x in theta:  \\n print(\"x in theta\", x, theta)  \\n return unify(var, theta[x], theta)   else:  \\n theta[var] = x  \\n print(\"not in theta\", theta[var])   return theta  \\n  \\n  \\ndef check_theta(theta):  \\n for entry in theta:  \\n if variable(theta[entry]):  \\n if theta[entry] in theta:  \\n print(\"in check_theta. theta changed\")   theta[entry] = theta[theta[entry]]   return theta  \\n  \\n  \\ndef unify(x, y, theta):  \\n print(\"\\\\tunify\", x, y, theta)  \\n if theta == None: \\n print(\"\\\\tin theta is None\")  \\n return None  \\n elif x == y:  \\n print(\"\\\\tin x=y\")  \\n return check_theta(theta)  \\n elif variable(x) is True:  \\n print(\"\\\\tin variable(x)\")  \\n return unify_var(x, y, theta)  \\n elif variable(y) is True:  \\n print(\"\\\\tin variable(y)\")  \\n return unify_var(y, x, theta)  \\n elif compound(x) and compound(y):  \\n print(\"\\\\tin compound\")  \\n x_args = []  \\n temp = x.partition(\\'(\\')[-1].rpartition(\\')\\')[0]   for item in temp.split(\\',\\'):  \\n x_args.append(item)  \\n y_args = []  \\n temp = y.partition(\\'(\\')[-1].rpartition(\\')\\')[0]   for item in temp.split(\\',\\'):  \\n y_args.append(item)  \\n x_op = x.partition(\\'(\\')[0]  \\n y_op = y.partition(\\'(\\')[0]  \\n return unify(x_args, y_args, unify(x_op, y_op, theta))   elif list(x) and list(y):  \\n print(\"\\\\tin list\")  \\n return unify(x[1:], y[1:], unify(x[0], y[0], theta))   else:  \\n print(\"\\\\tin else\")  \\n return None  \\n  \\n  \\ndef fol_bc_ask(query, theta):  \\n global kb  \\n global list_of_predicates  \\n global list_of_explored_rules  \\n  \\n print(\"Backward Chaining\")  \\n list_of_rules = fetch_rules(query)  \\n for rule in list_of_rules:  \\n print(\"taken RULE\", rule)  \\n list_of_explored_rules = []  \\n list_of_explored_rules.append(query)  \\n print(\"\\\\t\",query, \"added to list_of_explored_rules\")   lhs = rule.partition(\\'=>\\')[0]  \\n rhs = rule.partition(\\'=>\\')[2]  \\n print(\"lhs: \", lhs, \" rhs: \", rhs)  \\n print(\"theta in rule\", theta)  \\n theta1 = unify(rhs, query, theta) \\n if theta1 != None:  \\n list_of_premises = lhs.split(\\'^\\')  \\n print(\"list_of_premises: \", list_of_premises)   theta2 = fol_bc_and(theta1, list_of_premises)   if theta2 != None:  \\n return theta2  \\n  \\n print(\"None of the rules worked out\", query)  \\n return None  \\n  \\ndef fol_bc_and(theta, list_of_premises):  \\n global kb  \\n global list_of_predicates  \\n  \\n print(\"\\\\tand: \", list_of_premises)  \\n print(\"\\\\ttheta: \", theta)  \\n if theta == None:  \\n return None  \\n else:  \\n if list_of_premises != []:  \\n temp_list = []  \\n for each_premise in list_of_premises:  \\n temp = subst(theta, each_premise)  \\n temp_list.append(temp)  \\n list_of_premises = temp_list  \\n first_premise = list_of_premises[0]  \\n rest_premise = list_of_premises[1:]  \\n subs = list_of_premises[0]  \\n if subs != \\'()\\':  \\n if subs in list_of_explored_rules:  \\n print(subs, \" already in list_of_explored_rules\")   return None  \\n else:  \\n print(subs, \" added to list_of_explored_rules\")   list_of_explored_rules.append(subs)   theta = fol_bc_or_sub(subs, {}, rest_premise)   else:  \\n return theta  \\n return theta  \\n  \\n  \\ndef fol_bc_or_sub(query, theta, rest):  \\n global kb  \\n global list_of_predicates  \\n  \\n print(\"\\\\tOR sub\")  \\n list_of_rules = fetch_rules(query)  \\n print(\"\\\\tLIST_OF_RULES\", list_of_rules)  \\n for rule in list_of_rules: \\n print(\"\\\\tRULE\", rule)  \\n lhs = rule.partition(\\'=>\\')[0]  \\n rhs = rule.partition(\\'=>\\')[2]  \\n print(\"\\\\n\\\\tlhs: \", lhs, \" rhs: \", rhs)   print(\"\\\\ntheta in rule\", theta)  \\n theta1 = unify(rhs, query, deepcopy(theta))   if theta1 != None:  \\n list_of_premises = lhs.split(\\'^\\')   print(\"\\\\tlist_of_premises: \", list_of_premises)   theta2 = fol_bc_and(theta1, list_of_premises)   theta3 = fol_bc_and(theta2, rest)   if theta3 != None:  \\n return theta3  \\n  \\n print(\"\\\\tNone of the rules worked out\", query)   return None  \\n  \\n  \\ndef add_to_kb(knowledge_base):  \\n global kb  \\n global list_of_predicates  \\n  \\n for sentence in knowledge_base:  \\n if \\'=>\\' not in sentence:  \\n predicate = sentence.partition(\\'(\\')[0]   if predicate not in list_of_predicates:   conc = []  \\n prem = []  \\n conc.append(\"=>\" + sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}   list_of_predicates.append(predicate)   else:  \\n conc = kb[predicate][\\'conc\\']  \\n prem = kb[predicate][\\'prem\\']  \\n conc.append(\"=>\" + sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}   else:  \\n clauses = sentence.partition(\\'=>\\')   list_of_premises = clauses[0].split(\\'^\\')   conclusion = clauses[2]  \\n  \\n # for conclusion  \\n predicate = conclusion.partition(\\'(\\')[0]   if predicate not in list_of_predicates:   conc = []  \\n prem = []  \\n conc.append(sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}   list_of_predicates.append(predicate) \\n else:  \\n conc = kb[predicate][\\'conc\\']  \\n prem = kb[predicate][\\'prem\\']  \\n conc.append(sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}    \\n # for list_of_premises  \\n for premise in list_of_premises:  \\n predicate = premise.partition(\\'(\\')[0]   if predicate not in list_of_predicates:   conc = []  \\n prem = []  \\n prem.append(sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}   list_of_predicates.append(predicate)   else:  \\n conc = kb[predicate][\\'conc\\']   prem = kb[predicate][\\'prem\\']   prem.append(sentence)  \\n kb[predicate] = {\\'conc\\': conc, \\'prem\\': prem}    \\n  \\ndef variable(x):  \\n if not isinstance(x, str):  \\n return False  \\n else:  \\n if x.islower():  \\n return True  \\n else:  \\n return False  \\n  \\ndef standardize_variables(knowledge_base):  \\n label = 0  \\n result_knowledge_base = []  \\n for rule in knowledge_base:  \\n variable_names = {}  \\n lhs = rule.partition(\\'=>\\')[0]  \\n rhs = rule.partition(\\'=>\\')[2]  \\n premise = []  \\n for x in lhs.split(\\'^\\'):  \\n premise.append(x)  \\n result_premise = \"\"  \\n for term in premise:  \\n args = []  \\n result_term = \"\" + term.partition(\\'(\\')[0]   temp = term.partition(\\'(\\')[-1].rpartition(\\')\\')[0]   result_item = \"\"  \\n for item in temp.split(\\',\\'):  \\n args.append(item) \\n if variable(item):  \\n if item not in variable_names:  \\n variable_names[item] = \"x\" + repr(label)   item = \"x\" + repr(label)  \\n label = label + 1  \\n else:  \\n item = variable_names[item]  \\n result_item = result_item + item + \",\"  \\n result_item = result_item[:len(result_item) - 1]   result_term = result_term + \\'(\\' + result_item + \\')\\' + \\'^\\'   result_premise = result_premise + result_term   result_premise = result_premise[:len(result_premise) - 1]    \\n conclusion = []  \\n for x in rhs.split(\\'^\\'):  \\n conclusion.append(x)  \\n if conclusion != [\\'\\']:  \\n result_premise = result_premise + \"=>\"  \\n for term in conclusion:  \\n args = []  \\n result_term = \"\" + term.partition(\\'(\\')[0]   temp = term.partition(\\'(\\')[-1].rpartition(\\')\\')[0]   result_item = \"\"  \\n for item in temp.split(\\',\\'):  \\n args.append(item)  \\n if variable(item):  \\n if item not in variable_names:  \\n variable_names[item] = \"x\" + repr(label)  item = \"x\" + repr(label)  \\nlabel = label + 1  \\n else:  \\n item = variable_names[item]  \\n result_item = result_item + item + \",\"   result_item = result_item[:len(result_item) - 1]   result_term = result_term + \\'(\\' + result_item + \\')\\' + \\'^\\'   result_premise = result_premise + result_term   result_premise = result_premise[:len(result_premise) - 1]    \\n result_knowledge_base.append(result_premise)  \\n return result_knowledge_base  \\n  \\n#Main  \\n  \\nfn=\"input.txt\"  \\nqueries = []  \\nknowledge_base = []  \\nf1=open(fn, \"r\")  \\ninput = f1.readlines()  \\ninput = [x.strip() for x in input] \\n  \\nfor i in range(1, int(input[0]) + 1):  \\n queries.append(input[i].replace(\" \", \"\"))  \\nfor i in range(int(input[0]) + 2, int(input[int(input[0]) + 1]) + int(input[0]) + 2):   knowledge_base.append(input[i].replace(\" \", \"\"))  \\nknowledge_base = standardize_variables(knowledge_base)  \\n  \\nkb = {}  \\nlist_of_predicates = []  \\nadd_to_kb(knowledge_base)  \\n  \\nfileOut = open(\"output.txt\", \"w\")  \\nfor query in queries:  \\n result = fol_bc_ask(query, {})  \\n if result != None:  \\n print(\"True\", result)  \\n fileOut.write(\"TRUE\" + \"\\\\n\")  \\n else:  \\n print(\"False\", result)  \\n fileOut.write(\"FALSE\" + \"\\\\n\")  \\n  \\nfileOut.close()  \\nf1.close'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}